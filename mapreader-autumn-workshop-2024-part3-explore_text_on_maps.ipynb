{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReader Autumn Workshop (2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up for Google Colab\n",
    "\n",
    ">**NOTE**: Skip this section if you are not using Google Colab!\n",
    "\n",
    "The below cells will:\n",
    "\n",
    "- Mount your Google Drive\n",
    "- Create a directory for the workshop\n",
    "- Change the working directory to the workshop directory\n",
    "- Download and install the required packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount your drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# set up MapReader_Autumn_Workshop directory\n",
    "!mkdir /content/drive/MyDrive/MapReader_Autumn_Workshop\n",
    "%cd /content/drive/MyDrive/MapReader_Autumn_Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/maps-as-data/mapreader-autumn-workshop-2024.git\n",
    "!pip install mapreader[dev]\n",
    "!pip install sentence-transformers scikit-learn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable custom widgets in colab\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define root directory\n",
    "\n",
    ">**NOTE**: Start from here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\timport google.colab\n",
    "\tROOT = './mapreader-autumn-workshop-2024'\n",
    "except ImportError:\n",
    "\tROOT = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Urban' vs 'Rural' text\n",
    "\n",
    "This notebook provides some examples of ways in which MapReader's patch classification and text spotting outputs can be combined.\n",
    "\n",
    "We will use our datasets to investigate the textual description of urban and rural landscapes by comparing text that often appears in the built environment (i.e. near building patches) versus the rest of the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "We will first need to load our building classification data and text spotting data.\n",
    "\n",
    "Since these were saved as `geojson` files we can load them with the `geopandas` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**: If you annotated/trained a model for something other than buildings, you will need to save the building predictions from [here](https://drive.google.com/file/d/1tqQAZ5rcHHel8WTRCEANRzGj88AGbXxA/view?usp=sharing) to the workshop directory in you Google Drive. You should then update the path in the cell below to \"./building_predicted_outputs.geojson\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load building patch predictions\n",
    "building_predictions = gpd.read_file(\"./predicted_outputs.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have text outputs for \"map_74427695.png\", we will filter our building predictions to only include the building patches from this map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_predictions = building_predictions[building_predictions[\"parent_id\"] == \"map_74427695.png\"] # filter for only map_74427695.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_predictions.head() # view the building predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our building predictions on the map image using `rasterio` and `matplotlib`. \n",
    "\n",
    "This will allow us to see the building patches that we will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rasterio.open(f\"{ROOT}/maps/map_74427695.tif\") # open the tiff file\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10)) # create a plot\n",
    "\n",
    "rasterio.plot.show(src, transform=src.transform, ax=ax) # plot the map image\n",
    "building_predictions.plot(\"predicted_label\", legend=True, cmap=\"viridis\", alpha=0.4, ax=ax) # plot the building predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the text predictions\n",
    "spotted_text = gpd.read_file(\"./deepsolo_text_predictions.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotted_text.head() # view the text predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find text on building patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identify text that appears on building patches by checking if the centroid of a text instance is within a patch classified as a building.\n",
    "\n",
    "This can give us an idea of text found in \"urban\" areas (i.e. near buildings) versus \"rural\" areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_patches = building_predictions[building_predictions[\"predicted_label\"] == \"building\"] # filter for patches that are predicted as \"building\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotted_text[\"close to building\"] = spotted_text[\"geometry\"].apply(lambda x: x.centroid.within(building_patches.unary_union)) # check if the centroid of the text is within a building patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotted_text.head() # view the text predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotted_text[\"close to building\"].value_counts() # count how many text instances are close to buildings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the text instances that appear on building patches on the map image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10)) # create a plot\n",
    "\n",
    "rasterio.plot.show(src, transform=src.transform, ax=ax) # plot the map\n",
    "spotted_text.plot(column=\"close to building\", legend=True, cmap=\"viridis\", ax=ax) # plot the text patches, coloured by whether they are close to a building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find probabilities of each word/phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have separated our text into these two categories, we can calculate the probability of each word/phrase appearing in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_text = spotted_text[spotted_text[\"close to building\"]] # filter for text that is on building patches\n",
    "other_text = spotted_text[~spotted_text[\"close to building\"]] # filter for text that is not on building patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts and probabilities of text for the building patches\n",
    "building_text_freq = building_text[\"text\"].value_counts()\n",
    "building_text_prob = building_text[\"text\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_text_prob.head(20) # view the top 20 probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts and probabilities of text for the non-building patches\n",
    "other_text_freq = other_text[\"text\"].value_counts()\n",
    "other_text_prob = other_text[\"text\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_text_prob.head(20) # view the top 20 probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the probabilities of each word/phrase appearing in the 'urban' and 'rural' categories to see if there are any words/phrases that are more likely to appear in one category than the other.\n",
    "\n",
    "e.g. We might expect \"street\" to be more likely to appear in the 'urban' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"street\" # choose a word to investigate\n",
    "word = word.upper() # convert to uppercase (since our predictions are all in uppercase)\n",
    "\n",
    "pd.DataFrame({\n",
    "        \"frequency\": [building_text_freq.get(word, 0), other_text_freq.get(word, 0)],\n",
    "        \"probability\": [building_text_prob.get(word, 0), other_text_prob.get(word, 0)]\n",
    "\t}, \n",
    "    index=[\"building\", \"other\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, we might expect \"field\" to be more likely to appear in the 'rural' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"field\" # choose a word to investigate\n",
    "word = word.upper() # convert to uppercase (since our predictions are all in uppercase)\n",
    "\n",
    "pd.DataFrame({\n",
    "        \"frequency\": [building_text_freq.get(word, 0), other_text_freq.get(word, 0)],\n",
    "        \"probability\": [building_text_prob.get(word, 0), other_text_prob.get(word, 0)]\n",
    "\t}, \n",
    "    index=[\"building\", \"other\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportional difference shows how much more likely a word/phrase is to appear in one category compared to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the proportional difference between building and non-building text probabilities\n",
    "proportional_diff = building_text_prob - other_text_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportional_diff.sort_values(ascending=False)[:20].plot(\n",
    "    kind=\"bar\", \n",
    "    ylabel=\"difference in probability\",\n",
    "    title=\"Words more likely to be near buildings\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportional_diff.sort_values()[:20].plot(\n",
    "    kind=\"bar\", \n",
    "    ylabel=\"difference in probability\",\n",
    "    title=\"Words less likely to be near buildings\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of what some of the abbreviations mean, please go to the NLS website: https://maps.nls.uk/os/abbrev/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visalizing the semantic of text on maps\n",
    "\n",
    "In the visualization below we encode each label to a vector using BERT-type language model. \n",
    "This generates a vector for each labels that approximates the 'meaning' of this label. \n",
    "Then we visualize these embeddigns in two dimensional space where you can explore the different semantic regions of the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = spotted_text.text.str.lower().tolist() # get the text labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained sentence transformer model\n",
    "# if you are working with a different language, you can change the model to a multilingual one\n",
    "# please refer to the documentation for more information: https://www.sbert.net/docs/pretrained_models.html\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "sentence_embeddings = model.encode(text_labels) # encode the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use TSNE to reduce the dimensionality of the embeddings so that we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_tsne = tsne.fit_transform(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to store the results\n",
    "data = pd.DataFrame(embeddings_tsne, columns=['x','y'])\n",
    "data['text'] = text_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() # view the results (the numbers in x and y are the coordinates of the text in the 2D space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the labels in 2D scatter plot\n",
    "fig = px.scatter(data, x=\"x\", y=\"y\", text='text', width=1000, height=1000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize only the text labels in 2D scatter plot\n",
    "data_text = data[data.text.str.isalpha()] # filter for text labels that contain only alphabetic characters i.e. remove numbers and special characters\n",
    "\n",
    "fig = px.scatter(data_text, x=\"x\", y=\"y\", text='text', width=1000, height=1000,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize only the unique text labels in 2D scatter plot\n",
    "data_text_unique =data[data.text.str.isalpha()].drop_duplicates(subset='text') # as above plus remove duplicates\n",
    "\n",
    "fig = px.scatter(data_text_unique, x=\"x\", y=\"y\", text='text', width=1000, height=1000,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mr_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
